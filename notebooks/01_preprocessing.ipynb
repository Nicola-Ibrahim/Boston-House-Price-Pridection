{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROC_TRAIN_DATA_PATH = \"../data/processed/1__preprocessed_df_trina.pkl\"\n",
    "PROC_TEST_DATA_PATH = \"../data/processed/1__preprocessed_df_test.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/raw/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_duplicates(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Remove duplicates values if exist\"\"\"\n",
    "    data = data.drop_duplicates()\n",
    "    return data\n",
    "\n",
    "df_train_modified = remove_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change missing values in some features to corresponding values given in data description file\n",
    "def fill_cat_missing_values(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filling the missing values in categorical variables\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    data:pd.DataFrame passing data to be processed\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "\n",
    "    cat_fill_missing_vals = {\n",
    "        'PoolQC': 'No Pool',\n",
    "        'Fence': 'No Fence',\n",
    "        'MiscFeature': 'None',\n",
    "        'Alley':'No alley access',\n",
    "        'FireplaceQu' : 'No Fireplace',\n",
    "        'GarageFinish' : 'No Garage',\n",
    "        'GarageCond' : 'No Garage',\n",
    "        'GarageQual' : 'No Garage',\n",
    "        'GarageType' : 'No Garage',\n",
    "        'BsmtExposure' : 'No Basement',\n",
    "        'BsmtFinType2' : 'No Basement',\n",
    "        'BsmtQual' : 'No Basement',\n",
    "        'BsmtCond' : 'No Basement',\n",
    "        'BsmtFinType1' : 'No Basement',\n",
    "        'MasVnrType' : 'None',\n",
    "    }\n",
    "\n",
    "    # for col, fill_val in cat_fill_missing_vals.items():\n",
    "    #     data[col] = data[col].fillna(fill_val)\n",
    "    cols = list(cat_fill_missing_vals.keys())\n",
    "    data[cols] = data[cols].apply(lambda col: col.fillna(cat_fill_missing_vals[col.name]))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def fill_num_missing_values(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filling the missing values in numerical variables\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    data:pd.DataFrame passing data to be processed\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # Fill by mean for MasVnrArea feature\n",
    "    data['MasVnrArea'] = data.groupby(by='MasVnrType')['MasVnrArea'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "\n",
    "    return data\n",
    "    \n",
    "df_train = fill_cat_missing_values(df_train)\n",
    "df_train = fill_num_missing_values(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove vars and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vars(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove variables from data\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    data:pd.DataFrame passing data to be processed\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # Drop LotFrontage & GarageYrBlt features\n",
    "    if({'LotFrontage','GarageYrBlt'}.issubset(data.columns) == False):\n",
    "        return\n",
    "\n",
    "    data = data.drop(columns=['LotFrontage','GarageYrBlt'])\n",
    "    return data\n",
    "\n",
    "def remove_values(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove values from the data\n",
    "    \"\"\" \n",
    "\n",
    "    data = data.copy()\n",
    "    # Remove Electrical feature\n",
    "    if('Electrical' not in data.columns):\n",
    "        return\n",
    "\n",
    "    droped_index = data[data['Electrical'].isnull()].index\n",
    "    proc_data = data.drop(index=droped_index)\n",
    "\n",
    "    return proc_data\n",
    "\n",
    "df_train = remove_vars(df_train)\n",
    "df_train = remove_values(df_train)\n",
    "\n",
    "df_test = remove_vars(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_manual(data:pd.DataFrame) -> list[pd.Index]:\n",
    "    indexes = data.query(\n",
    "                \"\"\"\n",
    "                LotArea > 100_000 | \\\n",
    "                BsmtFinSF1 > 5_000 | \\\n",
    "                BsmtFinSF2 > 1_400 | \\\n",
    "                TotalBsmtSF > 6_000 | \\\n",
    "                GrLivArea > 4_000 | \\\n",
    "                GarageArea > 1_300 | \\\n",
    "                WoodDeckSF > 800 | \\\n",
    "                EnclosedPorch > 500 | \\\n",
    "                SalePrice > 700_000 \n",
    "                \"\"\"\n",
    "            ).index\n",
    "\n",
    "    return indexes \n",
    "\n",
    "def remove_outliers(data:pd.DataFrame, indexes:list[pd.Index]) -> pd.DataFrame:\n",
    "    \"\"\"Remove outliers for the given indexes\"\"\"\n",
    "    return data.drop(index=indexes)\n",
    "\n",
    "\n",
    "df_train = remove_outliers(df_train, indexes=detect_outliers_manual(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from training data\n",
    "# categorical_feats_modified, numerical_feats_modified = split_features_by_type(df_train_modified)\n",
    "\n",
    "# Save the processed data\n",
    "df_train.to_pickle(PROC_TRAIN_DATA_PATH)\n",
    "df_test.to_pickle(PROC_TEST_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafb1f7618ea635952683f9de1ec2ad0605097bc28573cb02814b9f97cdb4857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
